{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005119\n"
     ]
    }
   ],
   "source": [
    "# ANALYSIS OF THE BROWN CORPUS\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk import FreqDist\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# nltk.download(\"brown\")\n",
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "sentences = brown.sents()\n",
    "tokens = brown.words()\n",
    "words = [token.lower() for token in tokens if any(c.isalpha() for c in token)]\n",
    "# filter out words that occur less than 10 times\n",
    "freq_dist = FreqDist(words)\n",
    "words_10 = [word for word, count in freq_dist.items() if count >= 10]\n",
    "words_10_unique = set(words_10)\n",
    "N = len(words) # number of words in the whole corpus\n",
    "print(N)\n",
    "word_index_dict = {}\n",
    "for i, word in enumerate(words_10_unique):\n",
    "    word_index_dict[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the counts of all successive pairs (w1, w2) to a numpy matrix of zeros\n",
    "counts = np.zeros((len(word_index_dict), len(word_index_dict)))\n",
    "\n",
    "# Count the number of occurrences of all successive pairs (w1, w2) in sentences\n",
    "for sentence in sentences:\n",
    "    for i in range(len(sentence) - 1):\n",
    "        w1 = sentence[i].lower()\n",
    "        w2 = sentence[i + 1].lower()\n",
    "        if w1 in word_index_dict and w2 in word_index_dict:\n",
    "            counts[word_index_dict[w1]][word_index_dict[w2]] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pmi\n",
    "pmi = np.zeros((len(word_index_dict), len(word_index_dict)))\n",
    "\n",
    "# Calculate the probabilities of words and word pairs\n",
    "word_counts = np.array([freq_dist[word] for word in words_10_unique])\n",
    "\n",
    "# Calculate the PMI values using vectorized operations\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    pmi = np.log2(counts * N / (word_counts[:, np.newaxis] * word_counts[np.newaxis, :]))\n",
    "    pmi[np.isnan(pmi)] = 0.0\n",
    "    pmi[np.isneginf(pmi)] = 0.0  # Set -inf values to zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 word pairs with the highest PMI values:\n",
      "nineteenth-century, immigration, PMI: 14.617006792305181\n",
      "presiding, elder, PMI: 14.710116196696664\n",
      "computing, allotments, PMI: 14.742537674389041\n",
      "willie, mays, PMI: 14.779063550414154\n",
      "peaceful, coexistence, PMI: 14.779063550414154\n",
      "phonologic, subsystems, PMI: 14.880041198138976\n",
      "carbon, tetrachloride, PMI: 14.954041779582752\n",
      "kohnstamm, reactivity, PMI: 14.990567655607867\n",
      "unwed, mothers, PMI: 15.032044291584025\n",
      "anionic, binding, PMI: 15.102433619475423\n",
      "drainage, ditch, PMI: 15.238495169051452\n",
      "puerto, rico, PMI: 15.353972386471387\n",
      "wtv, antigen, PMI: 15.4608875903879\n",
      "el, paso, PMI: 15.479503268555247\n",
      "lo, shu, PMI: 15.479503268555247\n",
      "herald, tribune, PMI: 15.586418472471758\n",
      "pathet, lao, PMI: 15.851472045942204\n",
      "simms, purdew, PMI: 15.851472045942204\n",
      "viet, nam, PMI: 15.938934887192543\n",
      "hong, kong, PMI: 16.479503268555245\n",
      "\n",
      "20 word pairs with the lowest PMI values:\n",
      "the, a, PMI: -10.657060828365204\n",
      "of, of, PMI: -10.365317843492496\n",
      "the, and, PMI: -9.971968313530287\n",
      "and, and, PMI: -9.693932534612019\n",
      "the, in, PMI: -9.536604328472192\n",
      "the, is, PMI: -9.458887272554337\n",
      "a, in, PMI: -8.943661064388841\n",
      "his, the, PMI: -8.927849176549657\n",
      "of, to, PMI: -8.88815609653293\n",
      "the, i, PMI: -8.489807887935196\n",
      "he, of, PMI: -8.434174329231752\n",
      "of, he, PMI: -8.434174329231752\n",
      "of, for, PMI: -8.425231819388525\n",
      "the, not, PMI: -8.326085637944706\n",
      "an, the, PMI: -8.024357157403005\n",
      "to, was, PMI: -7.996802283543943\n",
      "to, he, PMI: -7.957012582272186\n",
      "to, for, PMI: -7.948070072428959\n",
      "of, on, PMI: -7.931938388051039\n",
      "on, of, PMI: -7.931938388051039\n"
     ]
    }
   ],
   "source": [
    "# Find the indices of the 20 highest and lowest PMI values\n",
    "highest_pmi_indices = np.unravel_index(np.argsort(pmi.ravel())[-20:], pmi.shape)\n",
    "lowest_pmi_indices = np.unravel_index(np.argsort(pmi.ravel())[:20], pmi.shape)\n",
    "\n",
    "print(\"20 word pairs with the highest PMI values:\")\n",
    "for i, j in zip(*highest_pmi_indices):\n",
    "    w1 = list(word_index_dict.keys())[list(word_index_dict.values()).index(i)]\n",
    "    w2 = list(word_index_dict.keys())[list(word_index_dict.values()).index(j)]\n",
    "    print(f\"{w1}, {w2}, PMI: {pmi[i, j]}\")\n",
    "\n",
    "print(\"\\n20 word pairs with the lowest PMI values:\")\n",
    "for i, j in zip(*lowest_pmi_indices):\n",
    "    w1 = list(word_index_dict.keys())[list(word_index_dict.values()).index(i)]\n",
    "    w2 = list(word_index_dict.keys())[list(word_index_dict.values()).index(j)]\n",
    "    print(f\"{w1}, {w2}, PMI: {pmi[i, j]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e6450fb800efe70b605ff38d11b2a0ed9ac58de58ae6ae091b03065513c90f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
